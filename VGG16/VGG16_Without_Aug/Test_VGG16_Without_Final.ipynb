{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQbzd1pDgo8M"
   },
   "source": [
    "# Test VGG16 Architcture without Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VZaoqItRvqCl"
   },
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_kWmeailsG3Y"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zzktYqozr-25"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tiQjtCJhRUOW",
    "outputId": "ad2dc922-35e8-4214-c909-05f7002c648a"
   },
   "outputs": [],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DacdHFzWRUOW",
    "outputId": "3d32d861-3f79-442e-ae67-d9051d0cc92b"
   },
   "outputs": [],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ET70JsbWRUOX",
    "outputId": "9bda618b-51c0-4088-a6b9-caab53bb7d91"
   },
   "outputs": [],
   "source": [
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q5lh0MO0RUOX",
    "outputId": "281eb2e3-26ce-4338-f8d4-c64d307cd823"
   },
   "outputs": [],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "znlkc8FwRUOY",
    "outputId": "72ff69d3-8c6b-4779-90b5-dd2d7c2fdf65"
   },
   "outputs": [],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nuoA12Q2bP1U"
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mOqTo1Xrv2UI"
   },
   "source": [
    "# Designing a Convolution Neural Network (CNN): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mdAPg-cshjl9"
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
    "\n",
    "VGG_types = {\n",
    "    \"VGG11\": [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
    "    \"VGG13\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
    "    \"VGG16\": [\n",
    "        64,\n",
    "        64,\n",
    "        \"M\",\n",
    "        128,\n",
    "        128,\n",
    "        \"M\",\n",
    "        256,\n",
    "        256,\n",
    "        256,\n",
    "        \"M\",\n",
    "        512,\n",
    "        512,\n",
    "        512,\n",
    "        \"M\",\n",
    "        512,\n",
    "        512,\n",
    "        512,\n",
    "        \"M\",\n",
    "    ],\n",
    "    \"VGG19\": [\n",
    "        64,\n",
    "        64,\n",
    "        \"M\",\n",
    "        128,\n",
    "        128,\n",
    "        \"M\",\n",
    "        256,\n",
    "        256,\n",
    "        256,\n",
    "        256,\n",
    "        \"M\",\n",
    "        512,\n",
    "        512,\n",
    "        512,\n",
    "        512,\n",
    "        \"M\",\n",
    "        512,\n",
    "        512,\n",
    "        512,\n",
    "        512,\n",
    "        \"M\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "class VGG_net(nn.Module):\n",
    "    def __init__(self, in_channels=1, num_classes=3):\n",
    "        super(VGG_net, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.conv_layers = self.create_conv_layers(VGG_types[\"VGG16\"])\n",
    "\n",
    "        self.fcs = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fcs(x)\n",
    "        return x\n",
    "\n",
    "    def create_conv_layers(self, architecture):\n",
    "        layers = []\n",
    "        in_channels = self.in_channels\n",
    "\n",
    "        for x in architecture:\n",
    "            if type(x) == int:\n",
    "                out_channels = x\n",
    "\n",
    "                layers += [\n",
    "                    nn.Conv2d(\n",
    "                        in_channels=in_channels,\n",
    "                        out_channels=out_channels,\n",
    "                        kernel_size=(3, 3),\n",
    "                        stride=(1, 1),\n",
    "                        padding=(1, 1),\n",
    "                    ),\n",
    "                    nn.BatchNorm2d(x),\n",
    "                    nn.ReLU(),\n",
    "                ]\n",
    "                in_channels = x\n",
    "            elif x == \"M\":\n",
    "                layers += [nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))]\n",
    "\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eKE-A08T0xD1"
   },
   "outputs": [],
   "source": [
    "model = VGG_net()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DojucvH9RUOd"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(r\"C:\\Users\\HP\\Desktop\\Model\\VGG16\\VGG16_Without_Aug\\VGG16_.pth\", map_location={'cuda:0': 'cpu'}))\n",
    "\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QCzbEouSRUOd"
   },
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MWmRv1soRUOd"
   },
   "outputs": [],
   "source": [
    "def make_prediciton(image_path):\n",
    "    image = Image.open(image_path).convert(\"L\")\n",
    "    pretrained_size = 224\n",
    "    pretrained_means = [0.5]\n",
    "    pretrained_stds = [0.5]\n",
    "\n",
    "    train_transforms = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5),(0.5)),\n",
    "            ])\n",
    "        \n",
    "    image = train_transforms(image)    \n",
    "    image = image.reshape(1, 1, 224, 224)\n",
    "    predict = model(image)\n",
    "    softmax = nn.Softmax(dim=1)\n",
    "    predict = softmax(predict)\n",
    "    probability , prediction = torch.max(predict, dim = 1)\n",
    "    #converting torch tensor into numpy array\n",
    "    probability = probability.detach().numpy()[0]\n",
    "    prediction = prediction.detach().numpy()[0]\n",
    "    \n",
    "    return probability, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make_prediciton(test_dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iptkJPsARUOe"
   },
   "outputs": [],
   "source": [
    "make_prediciton(r\"C:\\Users\\HP\\Desktop\\Model\\DATASET\\Testing\\malignant\\malignant (47).png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mGJYqw9PRUOe"
   },
   "outputs": [],
   "source": [
    "make_prediciton(r\"C:\\Users\\HP\\Desktop\\Model\\DATASET\\Testing\\benign\\benign (1).png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v-gZ6A8IRUOe"
   },
   "outputs": [],
   "source": [
    "#Wrong Prediction\n",
    "make_prediciton(r\"C:\\Users\\HP\\Desktop\\Model\\DATASET\\Testing\\normal\\normal (1).png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "epochs = 30\n",
    "num_classes = 3\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPU or GPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5),(0.5)),\n",
    "                       ])\n",
    "\n",
    "\n",
    "valid_transforms = transforms.Compose([\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.Grayscale(num_output_channels=1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5),(0.5)),\n",
    "                       ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nFnoCzbrRUOe"
   },
   "outputs": [],
   "source": [
    "test_dataset = torchvision.datasets.ImageFolder(root= r\"C:\\Users\\HP\\Desktop\\Model\\DATASET\\Testing\", transform = test_transforms)\n",
    "# test_dataset = torchvision.datasets.ImageFolder(root= r\"C:\\Users\\HP\\Desktop\\Model\\DATASET\", transform = test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MQONRLqi-CBB"
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "target = []\n",
    "probabilities = []\n",
    "individual_prob = []\n",
    "\n",
    "for images, labels in tqdm(test_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images)\n",
    "            outputs = nn.Softmax(dim=1)(outputs)\n",
    "            prob, predicted = torch.max(outputs.data, 1)\n",
    "            #Tensor from GPU to CPU by converting pytorch numpy to tensor array\n",
    "            predicted = predicted.cpu().numpy()\n",
    "            outputs = outputs.cpu().detach().numpy()\n",
    "            prob = prob.cpu().detach().numpy()\n",
    "            labels = labels.cpu().numpy()\n",
    "            preds.append(predicted)\n",
    "            target.append(labels)\n",
    "            #Finding probabilies for each probabilities\n",
    "            probabilities.append(list(outputs))\n",
    "            individual_prob.append(list(prob))\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YyrbZUpxBOPL"
   },
   "source": [
    "Converting 2-D into 1-D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rCANQc8EAmci"
   },
   "outputs": [],
   "source": [
    "probabilities1 = []\n",
    "individual_prob1 = []\n",
    "preds1 = []\n",
    "target1 = []\n",
    "\n",
    "for i in probabilities:\n",
    "  for j in i:\n",
    "    probabilities1.append(j)\n",
    "\n",
    "for i in individual_prob:\n",
    "  for j in i:\n",
    "    individual_prob1.append(j)\n",
    "    \n",
    "for i in preds:\n",
    "  for j in i:\n",
    "    preds1.append(j)\n",
    "    \n",
    "for i in target:\n",
    "  for j in i:\n",
    "    target1.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BDXdtQFn-ZIF"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(target1,preds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gOOsOkGX-ZoB"
   },
   "outputs": [],
   "source": [
    "print(classification_report(target1,preds1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J5E6N9z3-b_n"
   },
   "outputs": [],
   "source": [
    "confusion_matrix(target1,preds1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BIjmh-su0Yyz"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "from sklearn .metrics import roc_auc_score, roc_curve\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "def plot_cm(confusion):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.set(font_scale=1.2)\n",
    "    sns.heatmap(confusion, annot=True, fmt=\"d\", cmap=\"Greens\", square=True, \n",
    "                cbar=False, annot_kws={\"size\": 12}, linewidths=0.5)\n",
    "    plt.xlabel('Predicted labels', fontsize=14)\n",
    "    plt.ylabel('True labels', fontsize=14)\n",
    "    plt.title('Confusion Matrix', fontsize=16)\n",
    "    classes = ['Benign', 'Malignant', 'Normal'] \n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks + 0.5, classes, fontsize=12)\n",
    "    plt.yticks(tick_marks + 0.5, classes, fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Assuming target1 and preds1 are the true labels and predicted labels, respectively\n",
    "confusion = confusion_matrix(target1, preds1, labels=[0, 1, 2])\n",
    "plot_cm(confusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1WjR2P630fJw"
   },
   "outputs": [],
   "source": [
    "auc = np.round(roc_auc_score(target1, probabilities1, multi_class = 'ovr'), 3)\n",
    "print(\"Auc score for our sample data is {}\". format(auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "81Npw1dNFwgG"
   },
   "outputs": [],
   "source": [
    "probabilities2 = np.array([i for i in probabilities1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4e2DWJk57_Vb"
   },
   "outputs": [],
   "source": [
    "def plot_multiclass_roc(y_score, y_test, n_classes, figsize=(17, 6)):\n",
    "\n",
    "    # structures\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    threshold = dict()\n",
    "\n",
    "    for i in range(n_classes):    \n",
    "      fpr[i], tpr[i], threshold[i] = roc_curve(target1, probabilities2[:,i], pos_label=i)\n",
    "    # roc for each class\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    ax.plot([0, 1], [0, 1], 'k--')\n",
    "    ax.set_xlim([0.0, 1.0])\n",
    "    ax.set_ylim([0.0, 1.05])\n",
    "    ax.set_xlabel('False Positive Rate')\n",
    "    ax.set_ylabel('True Positive Rate')\n",
    "    ax.set_title('Receiver Operating Characteristic ')\n",
    "    for i in range(n_classes):\n",
    "        ax.plot(fpr[i], tpr[i], label = 'class '+ test_dataset.classes[i])\n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.grid(alpha=.4)\n",
    "    sns.despine()\n",
    "    plt.show()\n",
    "\n",
    "plot_multiclass_roc(probabilities2, target1, n_classes=3, figsize=(12,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GQi8vVtZHRBf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FIkhGpaXCoNo"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
